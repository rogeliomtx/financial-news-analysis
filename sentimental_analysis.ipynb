{"cells":[{"cell_type":"markdown","metadata":{"id":"ezO1ts889fno"},"source":["## Financial news categorization/sentiment analysis using NLP techniques\n","\n","\n","Sentiment analysis is the statistical analysis of simple sentiment\n","cues. Essentially, it involves making statistical analyses on polarized\n","statements (i.e., statements with a positive, negative and neutral sen\n","timent), which are usually collected in the form of social media posts,\n","reviews, and news articles. Financial sentiment analysis is a challenging task due to the specialized language and lack of labeled data in that domain.\n","\n","\n","In our case, we will focus on two different tasks.\n","\n","\n","1. **Category tagger**: Create a NLP classifier capable of assigning a financial category to a text derived from the financial industry.\n","\n","The Twitter Financial News dataset is an English-language dataset containing an annotated corpus of finance-related tweets. This dataset is used to classify finance-related tweets for their topic.\n","\n","    The dataset holds 21,107 documents annotated with 20 labels:\n","\n","topics = {\n","    \"LABEL_0\": \"Analyst Update\",\n","    \"LABEL_1\": \"Fed | Central Banks\",\n","    \"LABEL_2\": \"Company | Product News\",\n","    \"LABEL_3\": \"Treasuries | Corporate Debt\",\n","    \"LABEL_4\": \"Dividend\",\n","    \"LABEL_5\": \"Earnings\",\n","    \"LABEL_6\": \"Energy | Oil\",\n","    \"LABEL_7\": \"Financials\",\n","    \"LABEL_8\": \"Currencies\",\n","    \"LABEL_9\": \"General News | Opinion\",\n","    \"LABEL_10\": \"Gold | Metals | Materials\",\n","    \"LABEL_11\": \"IPO\",\n","    \"LABEL_12\": \"Legal | Regulation\",\n","    \"LABEL_13\": \"M&A | Investments\",\n","    \"LABEL_14\": \"Macro\",\n","    \"LABEL_15\": \"Markets\",\n","    \"LABEL_16\": \"Politics\",\n","    \"LABEL_17\": \"Personnel Change\",\n","    \"LABEL_18\": \"Stock Commentary\",\n","    \"LABEL_19\": \"Stock Movement\"\n","}\n","\n","2. **Sentiment tagger**: Create a NLP classifier capable of assigning a sentiment score (positive,negative,neutral) to text derived from the financial industry. Additionally, we will use a powerful pre-trained model, finetuned on financial data, to assign scores to financial headlines, data from social media posts, etc ...\n"]},{"cell_type":"markdown","metadata":{"id":"43XAZnWc9fnp"},"source":["## Pre-requisites:\n","\n","\n","High level requirements of Python library.\n","\n","    - Pytorch\n","    - HuggingFace Transformers library\n","    - Pandas\n","    - Numpy\n","    - Sklearn\n","    "]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":35539,"status":"ok","timestamp":1709467766771,"user":{"displayName":"Roger","userId":"07150139541907234973"},"user_tz":-60},"id":"aUONj8419fnp"},"outputs":[],"source":["# %%capture\n","# ! pip install pandas\n","# ! pip install numpy\n","# ! pip install matplotlib\n","# ! pip install scikit-learn\n","# ! pip install transformers\n","# ! pip install torch\n","# ! pip install tensorflow\n","# ! pip install tensorflow-metal"]},{"cell_type":"markdown","metadata":{"id":"YYbMCX6e9fnq"},"source":["## **Step 1: Pulling the data together**\n","\n","\n","Download and inspect the data from the various sources:\n","\n","1. Financial Phrasebank https://huggingface.co/datasets/financial_phrasebank. Humanly annotated\n","\n","2. Financial tweets topics dataset: https://huggingface.co/datasets/zeroshot/twitter-financial-news-topic/viewer/default/train?p=169. Humanly annotated\n","\n","Think of any pre-processing functions (\n","    Converting the text to lowercase,\n","    removing punctuation,\n","    tokenizing the text,\n","    removing stop words and empty strings,\n","    lemmatizing tokens.\n",") that you might need to apply for downstream tasks. As always, pick a framework for data analysis and data exploration."]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":7646,"status":"ok","timestamp":1709467704929,"user":{"displayName":"Roger","userId":"07150139541907234973"},"user_tz":-60},"id":"83l6oMya9fnq"},"outputs":[],"source":["import pandas as pd\n","import string\n","\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import WordNetLemmatizer\n","\n","import spacy\n","from spacy.lang.en import English\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, confusion_matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":608,"status":"ok","timestamp":1709467767374,"user":{"displayName":"Roger","userId":"07150139541907234973"},"user_tz":-60},"id":"P1339YAs9fnq","outputId":"485f0115-8235-44df-aa7d-edcdf22ca8f8"},"outputs":[],"source":["import nltk\n","nltk.download(\"wordnet\")\n","nltk.download('punkt')"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1709467767374,"user":{"displayName":"Roger","userId":"07150139541907234973"},"user_tz":-60},"id":"OzFLGYM19fnr","outputId":"82e8b3e8-a367-434f-8817-94a559dacce0"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>According to Gran , the company has no plans t...</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>For the last quarter of 2010 , Componenta 's n...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>In the third quarter of 2010 , net sales incre...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Operating profit rose to EUR 13.1 mn from EUR ...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Operating profit totalled EUR 21.1 mn , up fro...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2259</th>\n","      <td>Operating result for the 12-month period decre...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>2260</th>\n","      <td>HELSINKI Thomson Financial - Shares in Cargote...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>2261</th>\n","      <td>LONDON MarketWatch -- Share prices ended lower...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>2262</th>\n","      <td>Operating profit fell to EUR 35.4 mn from EUR ...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>2263</th>\n","      <td>Sales in Finland decreased by 10.5 % in Januar...</td>\n","      <td>negative</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2264 rows × 2 columns</p>\n","</div>"],"text/plain":["                                               sentence     label\n","0     According to Gran , the company has no plans t...   neutral\n","1     For the last quarter of 2010 , Componenta 's n...  positive\n","2     In the third quarter of 2010 , net sales incre...  positive\n","3     Operating profit rose to EUR 13.1 mn from EUR ...  positive\n","4     Operating profit totalled EUR 21.1 mn , up fro...  positive\n","...                                                 ...       ...\n","2259  Operating result for the 12-month period decre...  negative\n","2260  HELSINKI Thomson Financial - Shares in Cargote...  negative\n","2261  LONDON MarketWatch -- Share prices ended lower...  negative\n","2262  Operating profit fell to EUR 35.4 mn from EUR ...  negative\n","2263  Sales in Finland decreased by 10.5 % in Januar...  negative\n","\n","[2264 rows x 2 columns]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# read the finantial phrase bank data\n","# directory = 'FinancialPhraseBank-v1.0'\n","# files = os.listdir(directory)\n","# files = [file for file in files if file.startswith('Sentences_')]\n","\n","data = []\n","\n","with open(\"FinancialPhraseBank-v1.0/Sentences_AllAgree.txt\", \"r\", encoding=\"latin1\") as f:\n","    lines = f.readlines()\n","    for line in lines:\n","        sentence, label = line.strip().split(\"@\")\n","        data.append(dict(sentence=sentence, label=label))\n","\n","finantial = pd.DataFrame(data)\n","finantial"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1709467767374,"user":{"displayName":"Roger","userId":"07150139541907234973"},"user_tz":-60},"id":"GyAELto59fnr"},"outputs":[],"source":["def clean_text(text):\n","    # lowercase\n","    text = text.lower()\n","\n","    # remove punctuation\n","    text = text.translate(str.maketrans('', '', string.punctuation))\n","\n","    #tokenize text\n","    tokens = word_tokenize(text)\n","\n","    # Remove stop words and empty strings\n","    stop_words = spacy.lang.en.stop_words.STOP_WORDS\n","    tokens = [\n","        token for token in tokens\n","        if token not in stop_words\n","            and token.strip() != ''\n","    ]\n","\n","    # lemmatize tokens\n","    lemmatizer = WordNetLemmatizer()\n","    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n","\n","    return tokens"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1709467773730,"user":{"displayName":"Roger","userId":"07150139541907234973"},"user_tz":-60},"id":"SY8LOJsj9fns"},"outputs":[],"source":["# map the labels\n","labels = {\n","    \"neutral\": 0,\n","    \"positive\": 1,\n","    \"negative\": 2\n","}"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":525,"status":"ok","timestamp":1709467775823,"user":{"displayName":"Roger","userId":"07150139541907234973"},"user_tz":-60},"id":"rRtbnWXK9fns","outputId":"ef1b594a-5cd1-48bd-fc25-933a5e0e2d3d"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>label</th>\n","      <th>tokens</th>\n","      <th>cleaned_sentence</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>According to Gran , the company has no plans t...</td>\n","      <td>0</td>\n","      <td>[according, gran, company, plan, production, r...</td>\n","      <td>according gran company plan production russia ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>For the last quarter of 2010 , Componenta 's n...</td>\n","      <td>1</td>\n","      <td>[quarter, 2010, componenta, s, net, sale, doub...</td>\n","      <td>quarter 2010 componenta s net sale doubled eur...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>In the third quarter of 2010 , net sales incre...</td>\n","      <td>1</td>\n","      <td>[quarter, 2010, net, sale, increased, 52, eur,...</td>\n","      <td>quarter 2010 net sale increased 52 eur 2055 mn...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Operating profit rose to EUR 13.1 mn from EUR ...</td>\n","      <td>1</td>\n","      <td>[operating, profit, rose, eur, 131, mn, eur, 8...</td>\n","      <td>operating profit rose eur 131 mn eur 87 mn cor...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Operating profit totalled EUR 21.1 mn , up fro...</td>\n","      <td>1</td>\n","      <td>[operating, profit, totalled, eur, 211, mn, eu...</td>\n","      <td>operating profit totalled eur 211 mn eur 186 m...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2259</th>\n","      <td>Operating result for the 12-month period decre...</td>\n","      <td>2</td>\n","      <td>[operating, result, 12month, period, decreased...</td>\n","      <td>operating result 12month period decreased prof...</td>\n","    </tr>\n","    <tr>\n","      <th>2260</th>\n","      <td>HELSINKI Thomson Financial - Shares in Cargote...</td>\n","      <td>2</td>\n","      <td>[helsinki, thomson, financial, share, cargotec...</td>\n","      <td>helsinki thomson financial share cargotec fell...</td>\n","    </tr>\n","    <tr>\n","      <th>2261</th>\n","      <td>LONDON MarketWatch -- Share prices ended lower...</td>\n","      <td>2</td>\n","      <td>[london, marketwatch, share, price, ended, low...</td>\n","      <td>london marketwatch share price ended lower lon...</td>\n","    </tr>\n","    <tr>\n","      <th>2262</th>\n","      <td>Operating profit fell to EUR 35.4 mn from EUR ...</td>\n","      <td>2</td>\n","      <td>[operating, profit, fell, eur, 354, mn, eur, 6...</td>\n","      <td>operating profit fell eur 354 mn eur 688 mn 20...</td>\n","    </tr>\n","    <tr>\n","      <th>2263</th>\n","      <td>Sales in Finland decreased by 10.5 % in Januar...</td>\n","      <td>2</td>\n","      <td>[sale, finland, decreased, 105, january, sale,...</td>\n","      <td>sale finland decreased 105 january sale outsid...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2264 rows × 4 columns</p>\n","</div>"],"text/plain":["                                               sentence  label  \\\n","0     According to Gran , the company has no plans t...      0   \n","1     For the last quarter of 2010 , Componenta 's n...      1   \n","2     In the third quarter of 2010 , net sales incre...      1   \n","3     Operating profit rose to EUR 13.1 mn from EUR ...      1   \n","4     Operating profit totalled EUR 21.1 mn , up fro...      1   \n","...                                                 ...    ...   \n","2259  Operating result for the 12-month period decre...      2   \n","2260  HELSINKI Thomson Financial - Shares in Cargote...      2   \n","2261  LONDON MarketWatch -- Share prices ended lower...      2   \n","2262  Operating profit fell to EUR 35.4 mn from EUR ...      2   \n","2263  Sales in Finland decreased by 10.5 % in Januar...      2   \n","\n","                                                 tokens  \\\n","0     [according, gran, company, plan, production, r...   \n","1     [quarter, 2010, componenta, s, net, sale, doub...   \n","2     [quarter, 2010, net, sale, increased, 52, eur,...   \n","3     [operating, profit, rose, eur, 131, mn, eur, 8...   \n","4     [operating, profit, totalled, eur, 211, mn, eu...   \n","...                                                 ...   \n","2259  [operating, result, 12month, period, decreased...   \n","2260  [helsinki, thomson, financial, share, cargotec...   \n","2261  [london, marketwatch, share, price, ended, low...   \n","2262  [operating, profit, fell, eur, 354, mn, eur, 6...   \n","2263  [sale, finland, decreased, 105, january, sale,...   \n","\n","                                       cleaned_sentence  \n","0     according gran company plan production russia ...  \n","1     quarter 2010 componenta s net sale doubled eur...  \n","2     quarter 2010 net sale increased 52 eur 2055 mn...  \n","3     operating profit rose eur 131 mn eur 87 mn cor...  \n","4     operating profit totalled eur 211 mn eur 186 m...  \n","...                                                 ...  \n","2259  operating result 12month period decreased prof...  \n","2260  helsinki thomson financial share cargotec fell...  \n","2261  london marketwatch share price ended lower lon...  \n","2262  operating profit fell eur 354 mn eur 688 mn 20...  \n","2263  sale finland decreased 105 january sale outsid...  \n","\n","[2264 rows x 4 columns]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# process finantial data\n","fin_df = finantial.copy()\n","fin_df[\"tokens\"] = fin_df[\"sentence\"].apply(clean_text)\n","fin_df[\"cleaned_sentence\"] = fin_df[\"tokens\"].apply(lambda x: \" \".join(x))\n","\n","fin_df[\"label\"] = fin_df[\"label\"].map(labels)\n","fin_df"]},{"cell_type":"markdown","metadata":{"id":"A0Lw4Ejv9fns"},"source":["## **Step 2: Train and fine-tune various NLP classifiers on financial news datasets**\n","\n","\n","\n","#### **2.1 Let´s start with simple baseline (at your own choice)**. For example, build a logistic regression model based on pre-trained word embeddings or TF-IDF vectors of the financial news corpus **\n","\n","\n","Build a baseline model  with **Financial Phrasebank dataset**. What are the limitations of these baseline models?"]},{"cell_type":"markdown","metadata":{"id":"ZPoq14R39fnt"},"source":["### Baseline Model\n","Logistic Regression"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1709467778138,"user":{"displayName":"Roger","userId":"07150139541907234973"},"user_tz":-60},"id":"bw58D0_V9fns"},"outputs":[],"source":["vertorizer = TfidfVectorizer(max_features=1_000)"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":567,"status":"ok","timestamp":1709467780137,"user":{"displayName":"Roger","userId":"07150139541907234973"},"user_tz":-60},"id":"q11EE81-9fns"},"outputs":[],"source":["# prepare the tests\n","# train test split (80/20)\n","fin_train, fin_test = train_test_split(\n","    fin_df,\n","    test_size=0.2,\n","    random_state=42,\n","    stratify=fin_df[\"label\"]\n",")"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1709467781926,"user":{"displayName":"Roger","userId":"07150139541907234973"},"user_tz":-60},"id":"AFfy_iwv9fns"},"outputs":[],"source":["# train\n","fin_train_tfidf = vertorizer.fit_transform(fin_train[\"cleaned_sentence\"])\n","y_fin_train = fin_train[\"label\"]"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1709467783668,"user":{"displayName":"Roger","userId":"07150139541907234973"},"user_tz":-60},"id":"3EEroWLv9fns"},"outputs":[],"source":["# test\n","fin_test_tfidf = vertorizer.transform(fin_test[\"cleaned_sentence\"])\n","y_fin_test = fin_test[\"label\"]\n"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1709467785424,"user":{"displayName":"Roger","userId":"07150139541907234973"},"user_tz":-60},"id":"7mG9e7Jx9fnt","outputId":"0fe6915d-ebf4-485a-f0db-24d3104aa5fb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train accuracy: 0.89\n","Test accuracy: 0.83\n"]}],"source":["model = LogisticRegression()\n","model.fit(fin_train_tfidf, y_fin_train)\n","\n","y_train_pred = model.predict(fin_train_tfidf)\n","train_accuracy = accuracy_score(y_fin_train, y_train_pred)\n","\n","y_test_pred = model.predict(fin_test_tfidf)\n","test_accuracy = accuracy_score(y_fin_test, y_test_pred)\n","\n","print(f\"Train accuracy: {train_accuracy:.2f}\")\n","print(f\"Test accuracy: {test_accuracy:.2f}\")\n"]},{"cell_type":"markdown","metadata":{"id":"0K_-Dvf99fnt"},"source":["\n","#### **2.2 Compare the baseline with a pre-trained model that is specialized for the finance domain. Download and use the FinBERT model from Huggingfaces**\n","\n","Model source: https://huggingface.co/ProsusAI/finbert\n","\n","Once you have downloaded the model, run inference and compute performance metrics to get a sense of how the specialized pre-trained model fares against the baseline  model.  Use the HuggingFaces library to download the model and run inference on it. For large datasets or text sequences, CPU running time might be large.\n","\n","For more information on the model: Araci, D. (2019). FinBERT: Financial Sentiment Analysis with Pre-trained Language Models."]},{"cell_type":"markdown","metadata":{},"source":["### Bert model"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1507,"status":"ok","timestamp":1709467788890,"user":{"displayName":"Roger","userId":"07150139541907234973"},"user_tz":-60},"id":"o6YXg-QQ9fnt"},"outputs":[],"source":["import torch\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, random_split\n","\n","from transformers import BertTokenizer, BertForSequenceClassification, get_linear_schedule_with_warmup\n"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":336,"referenced_widgets":["2a8df236821e454fad3a3cfd5dcab400","d837a311980742fe8f250d61521fe953","d0362385031c47d7943ef15f0b3865c1","5aaae4485d5f4cdb99c1f41343aa080e","8d35c59d7f3544358dd841c867eb128a","92fd6e3bc7c04fac8f74b8ebb3c5b204","6e9a49d30ab64a3bb99ea21d2e04e7ee","bfd72d14f78a4b32a67daaf62e303659","f5b4f739ba0d450aba6ec23ec34a7499","b09bcf4273ca4f68b87b6432edb33d47","a7447f5689f24af6af59b8f4c546a413","1896c674c33449c88bc15cd87c9e86a0","14f24652ef704f24b62a0f53a2757f2f","7965925578d64599af3c8d8ca2877d59","7eb0946f2c394087827f4a5580be84eb","f1ea13f042f24af4a6a70026a96d842d","b09ef73f4fb54e4985f5652ed353a83d","3c36a721422643a8a844db6cb3b6b840","886c19388efb4cbc86d770e5373fa6ec","e1d0d6d4b4544a32ba1e0f6e7281d9c9","6b3cb3de7b0b4fc28cbba52fe6c1356f","2eef6deb0a9b4c248819d7ee0d8615e3","fa865818837749eb83085550cc464218","7a4d6c97f9464d6184b2d1d76faf171f","a54adea79e8a4c249d782eec3e9d0f37","f7e36014ac35457e9fcf96342d5a8b01","c61494619299461fbd01423bedd0734a","69974d68e4a14896a00c1d35f964c05f","23019cfce2524c238d8dcce294756cad","3ab82dee1ae34f7599a908efcc9d49a3","a77d166fa3ee45eeafb405d2e319ca79","a91fe71fb7cf4bd0b048b557158d782e","5706bb5f168e477bb0eae7e275849070","b4e48fc3fff74cf2ba3a515ef7e132ab","525844abce5948668fd1ce22f287384b","664939066eed4e589d098cf0f7857687","a69dd001e14b486a911383797df843d1","17f1d2479c8c4ed08b9195a866b10363","378a8e651a2d450aaa5f8d52447baf44","458dda8d76b0401ba7005f9f0bc8ad8a","980c2dc2d9da4b57b20cd709e935fbdc","8ec2a716b18340628469d69fad084219","24fb326b061f4b9d85b687d5cc9e4a5f","bddbb3349d4c4be593554a7795628e17","bd3f8154203a47e9a8b767abc9fec3d5","7ce66457b5334e0da42cd0db28ec00c5","ebcae7b262a143a6956f4190a9926afe","923bcab0332d4e099681d891f73f5afa","aed9e18de6d54f27ab0a871c30492ae3","82c39b444c3d44b28442dc8fca784e5e","76fb5090c2664a8187ac308dc7c932df","e38482019e254d57a38546e90d32d263","45df5879e4da42fc9cc42475b0a71655","621f6c89bcd245818d019330a96e07c9","952d24ab786945e1baec866e062ce520"]},"executionInfo":{"elapsed":8262,"status":"ok","timestamp":1709467799752,"user":{"displayName":"Roger","userId":"07150139541907234973"},"user_tz":-60},"id":"tPNp4AXq9fnt","outputId":"507bbbc6-c324-45cf-9beb-c27ce911caba"},"outputs":[],"source":["fb_tokenizer = BertTokenizer.from_pretrained('ProsusAI/finbert', do_lower_case=True)\n","fb_model = BertForSequenceClassification.from_pretrained('ProsusAI/finbert')"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":510,"status":"ok","timestamp":1709467800260,"user":{"displayName":"Roger","userId":"07150139541907234973"},"user_tz":-60},"id":"JlMfBCh79fnt"},"outputs":[],"source":["def predict_label(text): \n","    print(type(text))\n","    tokens = fb_tokenizer.encode_plus(\n","        text,\n","        add_special_tokens=False,\n","        return_tensors=\"pt\",\n","    )\n","    output = fb_model(**tokens)\n","    probabilities = torch.nn.functional.softmax(output.logits, dim=-1)\n","    label = torch.argmax(probabilities).item()\n","    return label"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1709467800260,"user":{"displayName":"Roger","userId":"07150139541907234973"},"user_tz":-60},"id":"e8Enb7X79fnt","outputId":"4d70820b-24fc-46dd-f95a-f552cbabc940"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>According to Gran , the company has no plans t...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>For the last quarter of 2010 , Componenta 's n...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>In the third quarter of 2010 , net sales incre...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Operating profit rose to EUR 13.1 mn from EUR ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Operating profit totalled EUR 21.1 mn , up fro...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2259</th>\n","      <td>Operating result for the 12-month period decre...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2260</th>\n","      <td>HELSINKI Thomson Financial - Shares in Cargote...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2261</th>\n","      <td>LONDON MarketWatch -- Share prices ended lower...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2262</th>\n","      <td>Operating profit fell to EUR 35.4 mn from EUR ...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2263</th>\n","      <td>Sales in Finland decreased by 10.5 % in Januar...</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2264 rows × 2 columns</p>\n","</div>"],"text/plain":["                                               sentence  label\n","0     According to Gran , the company has no plans t...      0\n","1     For the last quarter of 2010 , Componenta 's n...      1\n","2     In the third quarter of 2010 , net sales incre...      1\n","3     Operating profit rose to EUR 13.1 mn from EUR ...      1\n","4     Operating profit totalled EUR 21.1 mn , up fro...      1\n","...                                                 ...    ...\n","2259  Operating result for the 12-month period decre...      2\n","2260  HELSINKI Thomson Financial - Shares in Cargote...      2\n","2261  LONDON MarketWatch -- Share prices ended lower...      2\n","2262  Operating profit fell to EUR 35.4 mn from EUR ...      2\n","2263  Sales in Finland decreased by 10.5 % in Januar...      2\n","\n","[2264 rows x 2 columns]"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["# prepare the df\n","fb_df = finantial.copy()\n","fb_df[\"label\"] = fb_df[\"label\"].map(labels)\n","\n","fb_df"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":121796,"status":"ok","timestamp":1709467925733,"user":{"displayName":"Roger","userId":"07150139541907234973"},"user_tz":-60},"id":"1BFjIR-L9fnt","outputId":"615ec2d5-e86f-490c-986d-d93af4669a57"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>label</th>\n","      <th>predicted_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>According to Gran , the company has no plans t...</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>For the last quarter of 2010 , Componenta 's n...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>In the third quarter of 2010 , net sales incre...</td>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Operating profit rose to EUR 13.1 mn from EUR ...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Operating profit totalled EUR 21.1 mn , up fro...</td>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2259</th>\n","      <td>Operating result for the 12-month period decre...</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2260</th>\n","      <td>HELSINKI Thomson Financial - Shares in Cargote...</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2261</th>\n","      <td>LONDON MarketWatch -- Share prices ended lower...</td>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2262</th>\n","      <td>Operating profit fell to EUR 35.4 mn from EUR ...</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2263</th>\n","      <td>Sales in Finland decreased by 10.5 % in Januar...</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2264 rows × 3 columns</p>\n","</div>"],"text/plain":["                                               sentence  label  \\\n","0     According to Gran , the company has no plans t...      0   \n","1     For the last quarter of 2010 , Componenta 's n...      1   \n","2     In the third quarter of 2010 , net sales incre...      1   \n","3     Operating profit rose to EUR 13.1 mn from EUR ...      1   \n","4     Operating profit totalled EUR 21.1 mn , up fro...      1   \n","...                                                 ...    ...   \n","2259  Operating result for the 12-month period decre...      2   \n","2260  HELSINKI Thomson Financial - Shares in Cargote...      2   \n","2261  LONDON MarketWatch -- Share prices ended lower...      2   \n","2262  Operating profit fell to EUR 35.4 mn from EUR ...      2   \n","2263  Sales in Finland decreased by 10.5 % in Januar...      2   \n","\n","      predicted_label  \n","0                   2  \n","1                   0  \n","2                   2  \n","3                   0  \n","4                   2  \n","...               ...  \n","2259                1  \n","2260                1  \n","2261                0  \n","2262                1  \n","2263                2  \n","\n","[2264 rows x 3 columns]"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["# predict the label\n","fb_df[\"predicted_label\"] = fb_df[\"sentence\"].apply(predict_label)\n","fb_df"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1709467925733,"user":{"displayName":"Roger","userId":"07150139541907234973"},"user_tz":-60},"id":"S3ItFoWP9fnt","outputId":"09bdc572-5fa9-4753-dbba-8b0d8d8f00c7"},"outputs":[{"name":"stdout","output_type":"stream","text":["FinBERT accuracy: 0.05\n"]}],"source":["# accuracy\n","fb_accuracy = accuracy_score(fb_df[\"label\"], fb_df[\"predicted_label\"])\n","print(f\"FinBERT accuracy: {fb_accuracy:.2f}\")\n"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1709467925733,"user":{"displayName":"Roger","userId":"07150139541907234973"},"user_tz":-60},"id":"zU0PnI6I9fnt","outputId":"b5899cf2-5fd7-4e08-b2bb-0e9c541588a3"},"outputs":[{"data":{"text/plain":["array([[  32,   17, 1342],\n","       [ 405,   15,  150],\n","       [  31,  212,   60]])"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["# confusion matrix\n","matrix = confusion_matrix(fb_df[\"label\"], fb_df[\"predicted_label\"])\n","matrix"]},{"cell_type":"markdown","metadata":{"id":"AkQ_Uq5b9fnt"},"source":["#### **2.3 (Advanced) Fine-tune a pre-trained model such a base BERT model on a small labeled dataset**\n","\n","General-purpose models are not effective enough because of the specialized language used in a financial context. We hypothesize that pre-trained language models can help with this problem because they require fewer labeled examples and they can be further trained on domain-specific corpora.\n","\n","In recent years the NLP community has seen many breakthoughs in Natural Language Processing, especially the shift to transfer learning. Models like ELMo, fast.ai's ULMFiT, Transformer and OpenAI's GPT have allowed researchers to achieves state-of-the-art results on multiple benchmarks and provided the community with large pre-trained models with high performance. This shift in NLP is seen as NLP's ImageNet moment, a shift in computer vision a few year ago when lower layers of deep learning networks with million of parameters trained on a specific task can be reused and fine-tuned for other tasks, rather than training new networks from scratch.\n","\n","One of the most significant milestones in the evolution of NLP recently is the release of Google's BERT, which is described as the beginning of a new era in NLP. In our case, we are going to explore a pre-trained model called FinBERT, already tuned with a financial corpus. I specifically recommend the HuggingFace library for easeness of implementation.\n","\n","*What is HuggingFace?* Hugging Face’s Transformers is an open-source library that provides thousands of pre-trained models to perform various tasks on texts such as text classification, named entity recognition, translation, and more. The library has a unified, high-level API for these models and supports a wide range of languages and model architectures.\n","\n","\n","Here are various tutorials for finetuning BERT: https://drlee.io/fine-tuning-hugging-faces-bert-transformer-for-sentiment-analysis-69b976e6ac5d and https://skimai.com/fine-tuning-bert-for-sentiment-analysis/. I specially recommnend this one: http://mccormickml.com/2019/07/22/BERT-fine-tuning/\n","\n","The dataset where to finetune a BERT related model can be found in the previous cell: **Financial tweets topics dataset**\n","\n","*ALERT*: Running or training a large language model like BERT or FinBERT might incur in large CPU processing times. Although BERT is very large, complicated, and have millions of parameters, we might only need to fine-tune it in only 2-4 epochs. You can also explore Google colab, for limited acces to free GPUs, which might best suited for this task., specially if training required.\n","\n","Finally, compare the previous baseline with fine-tuned FinBERT"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load BertForSequenceClassification, the pretrained BERT model with a single\n","# linear classification layer on top.\n","model = BertForSequenceClassification.from_pretrained(\n","    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n","    num_labels=20, # The number of output labels--2 for binary classification.\n","                    # You can increase this for multi-class tasks.\n","    # output_attentions=False, # Whether the model returns attentions weights.\n","    # output_hidden_states=False, # Whether the model returns all hidden-states.\n",")\n","\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":708,"status":"ok","timestamp":1709467926438,"user":{"displayName":"Roger","userId":"07150139541907234973"},"user_tz":-60},"id":"qDKgyv8L9fnt","outputId":"1f675e45-c957-4704-931f-bbe1a26618fa"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Here are Thursday's biggest analyst calls: App...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Buy Las Vegas Sands as travel to Singapore bui...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Piper Sandler downgrades DocuSign to sell, cit...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Analysts react to Tesla's latest earnings, bre...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Netflix and its peers are set for a ‘return to...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text  label\n","0  Here are Thursday's biggest analyst calls: App...      0\n","1  Buy Las Vegas Sands as travel to Singapore bui...      0\n","2  Piper Sandler downgrades DocuSign to sell, cit...      0\n","3  Analysts react to Tesla's latest earnings, bre...      0\n","4  Netflix and its peers are set for a ‘return to...      0"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# read twitter data\n","twitter_train  = pd.read_csv(\"twitter/topic_train.csv\")\n","twitter_train.head()"]},{"cell_type":"code","execution_count":111,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1709467926438,"user":{"displayName":"Roger","userId":"07150139541907234973"},"user_tz":-60},"id":"acLgpcAE9fnu","outputId":"fc551dc1-a12f-4089-ba0c-cc7c72f207bd"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Analyst call of the day for @CNBCPro subscribe...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Loop upgrades CSX to buy, says it's a good pla...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>BofA believes we're already in a recession — a...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>JPMorgan sees these derivative plays as best w...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Morgan Stanley's Huberty sees Apple earnings m...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text  label\n","0  Analyst call of the day for @CNBCPro subscribe...      0\n","1  Loop upgrades CSX to buy, says it's a good pla...      0\n","2  BofA believes we're already in a recession — a...      0\n","3  JPMorgan sees these derivative plays as best w...      0\n","4  Morgan Stanley's Huberty sees Apple earnings m...      0"]},"execution_count":111,"metadata":{},"output_type":"execute_result"}],"source":["# read twitter data\n","twitter_valid = pd.read_csv(\"twitter/topic_valid.csv\")\n","twitter_valid.head()"]},{"cell_type":"code","execution_count":137,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1709467926438,"user":{"displayName":"Roger","userId":"07150139541907234973"},"user_tz":-60},"id":"LhoFwwCt9fnu"},"outputs":[],"source":["# concat the train and valid data\n","twitter = pd.concat([twitter_train, twitter_valid], axis=0, ignore_index=True)"]},{"cell_type":"markdown","metadata":{"id":"goWiQZ1n9fnu"},"source":["### Loading and Preprocessing the Data\n","Using https://mccormickml.com/2019/07/22/BERT-fine-tuning/"]},{"cell_type":"code","execution_count":138,"metadata":{"executionInfo":{"elapsed":500,"status":"ok","timestamp":1709467968783,"user":{"displayName":"Roger","userId":"07150139541907234973"},"user_tz":-60},"id":"klC8sL4w9fnu"},"outputs":[],"source":["MAX_TEXT_LEN = 128"]},{"cell_type":"code","execution_count":141,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13118,"status":"ok","timestamp":1709467982560,"user":{"displayName":"Roger","userId":"07150139541907234973"},"user_tz":-60},"id":"Acrf-_sk9fnu","outputId":"0e43245c-328b-41d0-dfa9-c02c6bec50e6"},"outputs":[{"data":{"text/plain":["147"]},"execution_count":141,"metadata":{},"output_type":"execute_result"}],"source":["max_text_len = twitter[\"text\"].apply(lambda x: tokenizer.encode(x, add_special_tokens=True)).apply(len).max()\n","max_text_len"]},{"cell_type":"code","execution_count":142,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":17145,"status":"ok","timestamp":1709467999704,"user":{"displayName":"Roger","userId":"07150139541907234973"},"user_tz":-60},"id":"1nOii3SI9fnu","outputId":"84b8f0c1-c907-46a4-b185-b332ef071cc9"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","      <th>tokens</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Here are Thursday's biggest analyst calls: App...</td>\n","      <td>0</td>\n","      <td>[input_ids, token_type_ids, attention_mask]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Buy Las Vegas Sands as travel to Singapore bui...</td>\n","      <td>0</td>\n","      <td>[input_ids, token_type_ids, attention_mask]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Piper Sandler downgrades DocuSign to sell, cit...</td>\n","      <td>0</td>\n","      <td>[input_ids, token_type_ids, attention_mask]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Analysts react to Tesla's latest earnings, bre...</td>\n","      <td>0</td>\n","      <td>[input_ids, token_type_ids, attention_mask]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Netflix and its peers are set for a ‘return to...</td>\n","      <td>0</td>\n","      <td>[input_ids, token_type_ids, attention_mask]</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>21102</th>\n","      <td>Dollar bonds of Chinese developers fall as str...</td>\n","      <td>3</td>\n","      <td>[input_ids, token_type_ids, attention_mask]</td>\n","    </tr>\n","    <tr>\n","      <th>21103</th>\n","      <td>Longer maturity Treasury yields have scope to ...</td>\n","      <td>3</td>\n","      <td>[input_ids, token_type_ids, attention_mask]</td>\n","    </tr>\n","    <tr>\n","      <th>21104</th>\n","      <td>Pimco buys €1bn of Apollo buyout loans from ba...</td>\n","      <td>3</td>\n","      <td>[input_ids, token_type_ids, attention_mask]</td>\n","    </tr>\n","    <tr>\n","      <th>21105</th>\n","      <td>Analysis: Banks' snubbing of junk-rated loan f...</td>\n","      <td>3</td>\n","      <td>[input_ids, token_type_ids, attention_mask]</td>\n","    </tr>\n","    <tr>\n","      <th>21106</th>\n","      <td>U.S. Treasury seeks information on digital ass...</td>\n","      <td>3</td>\n","      <td>[input_ids, token_type_ids, attention_mask]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>21107 rows × 3 columns</p>\n","</div>"],"text/plain":["                                                    text  label  \\\n","0      Here are Thursday's biggest analyst calls: App...      0   \n","1      Buy Las Vegas Sands as travel to Singapore bui...      0   \n","2      Piper Sandler downgrades DocuSign to sell, cit...      0   \n","3      Analysts react to Tesla's latest earnings, bre...      0   \n","4      Netflix and its peers are set for a ‘return to...      0   \n","...                                                  ...    ...   \n","21102  Dollar bonds of Chinese developers fall as str...      3   \n","21103  Longer maturity Treasury yields have scope to ...      3   \n","21104  Pimco buys €1bn of Apollo buyout loans from ba...      3   \n","21105  Analysis: Banks' snubbing of junk-rated loan f...      3   \n","21106  U.S. Treasury seeks information on digital ass...      3   \n","\n","                                            tokens  \n","0      [input_ids, token_type_ids, attention_mask]  \n","1      [input_ids, token_type_ids, attention_mask]  \n","2      [input_ids, token_type_ids, attention_mask]  \n","3      [input_ids, token_type_ids, attention_mask]  \n","4      [input_ids, token_type_ids, attention_mask]  \n","...                                            ...  \n","21102  [input_ids, token_type_ids, attention_mask]  \n","21103  [input_ids, token_type_ids, attention_mask]  \n","21104  [input_ids, token_type_ids, attention_mask]  \n","21105  [input_ids, token_type_ids, attention_mask]  \n","21106  [input_ids, token_type_ids, attention_mask]  \n","\n","[21107 rows x 3 columns]"]},"execution_count":142,"metadata":{},"output_type":"execute_result"}],"source":["def encode_text(text):\n","    tokens = fb_tokenizer.encode_plus(\n","        text,\n","        add_special_tokens=True,\n","        max_length=MAX_TEXT_LEN,\n","        return_tensors=\"pt\",\n","        padding='max_length',\n","        truncation=True,\n","        return_attention_mask=True,\n","    )\n","    return tokens\n","\n","# encode the text\n","twitter[\"tokens\"] = twitter[\"text\"].apply(encode_text)\n","twitter"]},{"cell_type":"code","execution_count":143,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":426},"executionInfo":{"elapsed":440797,"status":"error","timestamp":1709468440499,"user":{"displayName":"Roger","userId":"07150139541907234973"},"user_tz":-60},"id":"vt3AsO-L9fnu","outputId":"3f95d004-54bf-4f7d-d9d3-49d025fc653d"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","      <th>tokens</th>\n","      <th>input_ids</th>\n","      <th>attention_mask</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Here are Thursday's biggest analyst calls: App...</td>\n","      <td>0</td>\n","      <td>[input_ids, token_type_ids, attention_mask]</td>\n","      <td>[[tensor(101), tensor(2182), tensor(2024), ten...</td>\n","      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Buy Las Vegas Sands as travel to Singapore bui...</td>\n","      <td>0</td>\n","      <td>[input_ids, token_type_ids, attention_mask]</td>\n","      <td>[[tensor(101), tensor(4965), tensor(5869), ten...</td>\n","      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Piper Sandler downgrades DocuSign to sell, cit...</td>\n","      <td>0</td>\n","      <td>[input_ids, token_type_ids, attention_mask]</td>\n","      <td>[[tensor(101), tensor(11939), tensor(5472), te...</td>\n","      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Analysts react to Tesla's latest earnings, bre...</td>\n","      <td>0</td>\n","      <td>[input_ids, token_type_ids, attention_mask]</td>\n","      <td>[[tensor(101), tensor(18288), tensor(10509), t...</td>\n","      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Netflix and its peers are set for a ‘return to...</td>\n","      <td>0</td>\n","      <td>[input_ids, token_type_ids, attention_mask]</td>\n","      <td>[[tensor(101), tensor(20907), tensor(1998), te...</td>\n","      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>21102</th>\n","      <td>Dollar bonds of Chinese developers fall as str...</td>\n","      <td>3</td>\n","      <td>[input_ids, token_type_ids, attention_mask]</td>\n","      <td>[[tensor(101), tensor(7922), tensor(9547), ten...</td>\n","      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n","    </tr>\n","    <tr>\n","      <th>21103</th>\n","      <td>Longer maturity Treasury yields have scope to ...</td>\n","      <td>3</td>\n","      <td>[input_ids, token_type_ids, attention_mask]</td>\n","      <td>[[tensor(101), tensor(2936), tensor(16736), te...</td>\n","      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n","    </tr>\n","    <tr>\n","      <th>21104</th>\n","      <td>Pimco buys €1bn of Apollo buyout loans from ba...</td>\n","      <td>3</td>\n","      <td>[input_ids, token_type_ids, attention_mask]</td>\n","      <td>[[tensor(101), tensor(14255), tensor(12458), t...</td>\n","      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n","    </tr>\n","    <tr>\n","      <th>21105</th>\n","      <td>Analysis: Banks' snubbing of junk-rated loan f...</td>\n","      <td>3</td>\n","      <td>[input_ids, token_type_ids, attention_mask]</td>\n","      <td>[[tensor(101), tensor(4106), tensor(1024), ten...</td>\n","      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n","    </tr>\n","    <tr>\n","      <th>21106</th>\n","      <td>U.S. Treasury seeks information on digital ass...</td>\n","      <td>3</td>\n","      <td>[input_ids, token_type_ids, attention_mask]</td>\n","      <td>[[tensor(101), tensor(1057), tensor(1012), ten...</td>\n","      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>21107 rows × 5 columns</p>\n","</div>"],"text/plain":["                                                    text  label  \\\n","0      Here are Thursday's biggest analyst calls: App...      0   \n","1      Buy Las Vegas Sands as travel to Singapore bui...      0   \n","2      Piper Sandler downgrades DocuSign to sell, cit...      0   \n","3      Analysts react to Tesla's latest earnings, bre...      0   \n","4      Netflix and its peers are set for a ‘return to...      0   \n","...                                                  ...    ...   \n","21102  Dollar bonds of Chinese developers fall as str...      3   \n","21103  Longer maturity Treasury yields have scope to ...      3   \n","21104  Pimco buys €1bn of Apollo buyout loans from ba...      3   \n","21105  Analysis: Banks' snubbing of junk-rated loan f...      3   \n","21106  U.S. Treasury seeks information on digital ass...      3   \n","\n","                                            tokens  \\\n","0      [input_ids, token_type_ids, attention_mask]   \n","1      [input_ids, token_type_ids, attention_mask]   \n","2      [input_ids, token_type_ids, attention_mask]   \n","3      [input_ids, token_type_ids, attention_mask]   \n","4      [input_ids, token_type_ids, attention_mask]   \n","...                                            ...   \n","21102  [input_ids, token_type_ids, attention_mask]   \n","21103  [input_ids, token_type_ids, attention_mask]   \n","21104  [input_ids, token_type_ids, attention_mask]   \n","21105  [input_ids, token_type_ids, attention_mask]   \n","21106  [input_ids, token_type_ids, attention_mask]   \n","\n","                                               input_ids  \\\n","0      [[tensor(101), tensor(2182), tensor(2024), ten...   \n","1      [[tensor(101), tensor(4965), tensor(5869), ten...   \n","2      [[tensor(101), tensor(11939), tensor(5472), te...   \n","3      [[tensor(101), tensor(18288), tensor(10509), t...   \n","4      [[tensor(101), tensor(20907), tensor(1998), te...   \n","...                                                  ...   \n","21102  [[tensor(101), tensor(7922), tensor(9547), ten...   \n","21103  [[tensor(101), tensor(2936), tensor(16736), te...   \n","21104  [[tensor(101), tensor(14255), tensor(12458), t...   \n","21105  [[tensor(101), tensor(4106), tensor(1024), ten...   \n","21106  [[tensor(101), tensor(1057), tensor(1012), ten...   \n","\n","                                          attention_mask  \n","0      [[tensor(1), tensor(1), tensor(1), tensor(1), ...  \n","1      [[tensor(1), tensor(1), tensor(1), tensor(1), ...  \n","2      [[tensor(1), tensor(1), tensor(1), tensor(1), ...  \n","3      [[tensor(1), tensor(1), tensor(1), tensor(1), ...  \n","4      [[tensor(1), tensor(1), tensor(1), tensor(1), ...  \n","...                                                  ...  \n","21102  [[tensor(1), tensor(1), tensor(1), tensor(1), ...  \n","21103  [[tensor(1), tensor(1), tensor(1), tensor(1), ...  \n","21104  [[tensor(1), tensor(1), tensor(1), tensor(1), ...  \n","21105  [[tensor(1), tensor(1), tensor(1), tensor(1), ...  \n","21106  [[tensor(1), tensor(1), tensor(1), tensor(1), ...  \n","\n","[21107 rows x 5 columns]"]},"execution_count":143,"metadata":{},"output_type":"execute_result"}],"source":["twitter[\"input_ids\"] = twitter[\"tokens\"].apply(lambda x: x[\"input_ids\"])\n","twitter[\"attention_mask\"] = twitter[\"tokens\"].apply(lambda x: x[\"attention_mask\"])\n","\n","twitter"]},{"cell_type":"code","execution_count":144,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1709468446136,"user":{"displayName":"Roger","userId":"07150139541907234973"},"user_tz":-60},"id":"Xgm-dt-E9fnu","outputId":"36772c5c-ba7e-46c5-cc4e-3e0521ba497c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Buy Las Vegas Sands as travel to Singapore builds, Wells Fargo says  https://t.co/fLS2w57iCz\n","tensor([[  101,  4965,  5869,  7136, 13457,  2004,  3604,  2000,  5264, 16473,\n","          1010,  7051, 23054,  2758, 16770,  1024,  1013,  1013,  1056,  1012,\n","          2522,  1013, 13109,  2015,  2475,  2860, 28311, 18682,   102,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0]])\n"]}],"source":["print(\n","    twitter.loc[1, \"text\"],\n","    twitter.loc[1, \"input_ids\"],\n","    sep=\"\\n\"\n",")"]},{"cell_type":"code","execution_count":145,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1709468449448,"user":{"displayName":"Roger","userId":"07150139541907234973"},"user_tz":-60},"id":"lkQqV-5z9fnu","outputId":"4e09a375-f805-4995-903c-a366d3a538a7"},"outputs":[{"data":{"text/plain":["(tensor([[  101,  2182,  2024,  ...,     0,     0,     0],\n","         [  101,  4965,  5869,  ...,     0,     0,     0],\n","         [  101, 11939,  5472,  ...,     0,     0,     0],\n","         ...,\n","         [  101, 14255, 12458,  ...,     0,     0,     0],\n","         [  101,  4106,  1024,  ...,     0,     0,     0],\n","         [  101,  1057,  1012,  ...,     0,     0,     0]]),\n"," 21107)"]},"execution_count":145,"metadata":{},"output_type":"execute_result"}],"source":["input_ids = twitter[\"input_ids\"].tolist()\n","input_ids = torch.cat(input_ids, dim=0)\n","input_ids, len(input_ids)"]},{"cell_type":"code","execution_count":146,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1709468451672,"user":{"displayName":"Roger","userId":"07150139541907234973"},"user_tz":-60},"id":"Yci2N2tY9fnu","outputId":"08388af0-3343-45db-f21a-ede47f6f2630"},"outputs":[{"data":{"text/plain":["(tensor([[1, 1, 1,  ..., 0, 0, 0],\n","         [1, 1, 1,  ..., 0, 0, 0],\n","         [1, 1, 1,  ..., 0, 0, 0],\n","         ...,\n","         [1, 1, 1,  ..., 0, 0, 0],\n","         [1, 1, 1,  ..., 0, 0, 0],\n","         [1, 1, 1,  ..., 0, 0, 0]]),\n"," 21107)"]},"execution_count":146,"metadata":{},"output_type":"execute_result"}],"source":["attention_masks = twitter[\"attention_mask\"].tolist()\n","attention_masks = torch.cat(attention_masks, dim=0)\n","attention_masks, len(attention_masks)"]},{"cell_type":"code","execution_count":147,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":176},"executionInfo":{"elapsed":513,"status":"error","timestamp":1709470490191,"user":{"displayName":"Roger","userId":"07150139541907234973"},"user_tz":-60},"id":"1E0EEaiq9fnu","outputId":"44488c40-df58-409c-c75f-773bfc331cd3"},"outputs":[{"data":{"text/plain":["(tensor([0, 0, 0,  ..., 3, 3, 3]), 21107)"]},"execution_count":147,"metadata":{},"output_type":"execute_result"}],"source":["labels = twitter[\"label\"].tolist()\n","labels = torch.tensor(labels)\n","labels, len(labels)"]},{"cell_type":"markdown","metadata":{"id":"UYvkRh5y9fn4"},"source":["### Training & Validation Split\n","90% for training and 10% for validation"]},{"cell_type":"code","execution_count":148,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1709468456475,"user":{"displayName":"Roger","userId":"07150139541907234973"},"user_tz":-60},"id":"elQgSbQi9fn4","outputId":"d5026189-4a6f-450c-9b27-918a31aa1e09"},"outputs":[{"name":"stdout","output_type":"stream","text":["18,996 training samples\n","2,111 validation samples\n"]}],"source":["# Combine the training inputs into a TensorDataset.\n","dataset = TensorDataset(input_ids, attention_masks, labels)\n","\n","# Create a 90-10 train-validation split.\n","\n","# Calculate the number of samples to include in each set.\n","train_size = int(0.9 * len(dataset))\n","val_size = len(dataset) - train_size\n","\n","# Divide the dataset by randomly selecting samples.\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","\n","print('{:>5,} training samples'.format(train_size))\n","print('{:>5,} validation samples'.format(val_size))"]},{"cell_type":"code","execution_count":150,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1709468458316,"user":{"displayName":"Roger","userId":"07150139541907234973"},"user_tz":-60},"id":"2gDQ4eQk9fn4"},"outputs":[],"source":["# The DataLoader needs to know our batch size for training, so we specify it\n","# here. For fine-tuning BERT on a specific task, the authors recommend a batch\n","# size of 16 or 32.\n","batch_size = 32\n","\n","# Create the DataLoaders for our training and validation sets.\n","# We'll take training samples in random order.\n","train_dataloader = DataLoader(\n","    train_dataset,  # The training samples.\n","    sampler=RandomSampler(train_dataset), # Select batches randomly\n","    batch_size=batch_size # Trains with this batch size.\n",")\n","\n","# For validation the order doesn't matter, so we'll just read them sequentially.\n","validation_dataloader = DataLoader(\n","    val_dataset, # The validation samples.\n","    sampler=SequentialSampler(val_dataset), # Pull out batches sequentially.\n","    batch_size=batch_size # Evaluate with this batch size.\n",")"]},{"cell_type":"code","execution_count":151,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":625,"status":"ok","timestamp":1709468639051,"user":{"displayName":"Roger","userId":"07150139541907234973"},"user_tz":-60},"id":"Do-k7hz19fn4","outputId":"95be21d9-3c90-44a1-8e66-e6b4ecef0ee2"},"outputs":[{"name":"stdout","output_type":"stream","text":["The BERT model has 201 different named parameters.\n","\n","==== Embedding Layer ====\n","\n","bert.embeddings.word_embeddings.weight                  (30522, 768)\n","bert.embeddings.position_embeddings.weight                (512, 768)\n","bert.embeddings.token_type_embeddings.weight                (2, 768)\n","bert.embeddings.LayerNorm.weight                              (768,)\n","bert.embeddings.LayerNorm.bias                                (768,)\n","\n","==== First Transformer ====\n","\n","bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n","bert.encoder.layer.0.attention.self.query.bias                (768,)\n","bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n","bert.encoder.layer.0.attention.self.key.bias                  (768,)\n","bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n","bert.encoder.layer.0.attention.self.value.bias                (768,)\n","bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n","bert.encoder.layer.0.attention.output.dense.bias              (768,)\n","bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n","bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n","bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n","bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n","bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n","bert.encoder.layer.0.output.dense.bias                        (768,)\n","bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n","bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n","\n","==== Output Layer ====\n","\n","bert.pooler.dense.weight                                  (768, 768)\n","bert.pooler.dense.bias                                        (768,)\n","classifier.weight                                          (20, 768)\n","classifier.bias                                                (20,)\n"]}],"source":["# Get all of the model's parameters as a list of tuples.\n","params = list(model.named_parameters())\n","\n","print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n","\n","print('==== Embedding Layer ====\\n')\n","\n","for p in params[0:5]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== First Transformer ====\\n')\n","\n","for p in params[5:21]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== Output Layer ====\\n')\n","\n","for p in params[-4:]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"]},{"cell_type":"code","execution_count":152,"metadata":{"executionInfo":{"elapsed":502,"status":"ok","timestamp":1709468675102,"user":{"displayName":"Roger","userId":"07150139541907234973"},"user_tz":-60},"id":"gXHrsX4e9fn4"},"outputs":[],"source":["\n","# Note: AdamW is a class from the huggingface library (as opposed to pytorch)\n","# I believe the 'W' stands for 'Weight Decay fix\"\n","optimizer = torch.optim.AdamW(\n","    model.parameters(),\n","    lr=5e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n","    eps=1e-8 # args.adam_epsilon  - default is 1e-8.\n",")"]},{"cell_type":"code","execution_count":153,"metadata":{"executionInfo":{"elapsed":569,"status":"ok","timestamp":1709468680424,"user":{"displayName":"Roger","userId":"07150139541907234973"},"user_tz":-60},"id":"4_Wqww249fn4"},"outputs":[{"name":"stdout","output_type":"stream","text":["total_steps 1188\n","epochs 2\n"]}],"source":["# Number of training epochs. The BERT authors recommend between 2 and 4.\n","# We chose to run for 4, but we'll see later that this may be over-fitting the\n","# training data.\n","epochs = 2\n","\n","# Total number of training steps is [number of batches] x [number of epochs].\n","# (Note that this is not the same as the number of training samples).\n","total_steps = len(train_dataloader) * epochs\n","\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(\n","    optimizer,\n","    num_warmup_steps=0, # Default value in run_glue.py\n","    num_training_steps=total_steps\n",")\n","\n","print(\"total_steps\", total_steps)\n","print(\"epochs\", epochs)"]},{"cell_type":"markdown","metadata":{},"source":["### Aux functions"]},{"cell_type":"code","execution_count":154,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1709468683537,"user":{"displayName":"Roger","userId":"07150139541907234973"},"user_tz":-60},"id":"oJFNLa3v9fn4"},"outputs":[],"source":["import numpy as np\n","\n","# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"]},{"cell_type":"code","execution_count":155,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1709468685650,"user":{"displayName":"Roger","userId":"07150139541907234973"},"user_tz":-60},"id":"mQWOzdI59fn4"},"outputs":[],"source":["import time\n","import datetime\n","\n","def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","\n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"]},{"cell_type":"code","execution_count":156,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":665,"status":"ok","timestamp":1709469186012,"user":{"displayName":"Roger","userId":"07150139541907234973"},"user_tz":-60},"id":"NOXEaorhPvj6","outputId":"7139fedc-5b82-416d-93fe-540c8102bce7"},"outputs":[{"name":"stdout","output_type":"stream","text":["No GPU available, using the CPU instead.\n"]}],"source":["# If there's a GPU available...\n","if torch.cuda.is_available():\n","    # Tell PyTorch to use the GPU.\n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"]},{"cell_type":"markdown","metadata":{},"source":["### Training Loop"]},{"cell_type":"code","execution_count":157,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1709469200466,"user":{"displayName":"Roger","userId":"07150139541907234973"},"user_tz":-60},"id":"zFa_JxZFTcxC","outputId":"d23a73a1-10c2-4fe8-8063-80d9d18a8060"},"outputs":[{"name":"stdout","output_type":"stream","text":["env: CUDA_LAUNCH_BLOCKING=1\n"]}],"source":["%env CUDA_LAUNCH_BLOCKING=1"]},{"cell_type":"code","execution_count":158,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":408},"executionInfo":{"elapsed":4,"status":"error","timestamp":1709470267097,"user":{"displayName":"Roger","userId":"07150139541907234973"},"user_tz":-60},"id":"CHCbiN5jUcSk","outputId":"b797a708-8641-44b6-bc7a-5b2dea1631e2"},"outputs":[],"source":["import random\n","import numpy as np\n","\n","# This training code is based on the `run_glue.py` script here:\n","# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n","\n","# Set the seed value all over the place to make this reproducible.\n","seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","# We'll store a number of quantities such as training and validation loss,\n","# validation accuracy, and timings.\n","training_stats = []\n","\n","# Measure the total training time for the whole run.\n","total_t0 = time.time()"]},{"cell_type":"code","execution_count":159,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":367},"executionInfo":{"elapsed":491,"status":"error","timestamp":1709470208658,"user":{"displayName":"Roger","userId":"07150139541907234973"},"user_tz":-60},"id":"CX9F0csaOpuP","outputId":"0a00452d-ba72-4cb0-b44b-41ecd7d81be0"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","======== Epoch 1 / 2 ========\n","Training...\n","  Batch    40  of    594.    Elapsed: 0:02:15.\n","  Batch    80  of    594.    Elapsed: 0:04:27.\n","  Batch   120  of    594.    Elapsed: 0:06:39.\n","  Batch   160  of    594.    Elapsed: 0:08:52.\n","  Batch   200  of    594.    Elapsed: 0:11:04.\n","  Batch   240  of    594.    Elapsed: 0:13:16.\n","  Batch   280  of    594.    Elapsed: 0:15:31.\n","  Batch   320  of    594.    Elapsed: 0:17:46.\n","  Batch   360  of    594.    Elapsed: 0:19:59.\n","  Batch   400  of    594.    Elapsed: 0:22:13.\n","  Batch   440  of    594.    Elapsed: 0:24:26.\n","  Batch   480  of    594.    Elapsed: 0:26:39.\n","  Batch   520  of    594.    Elapsed: 0:29:05.\n","  Batch   560  of    594.    Elapsed: 0:31:18.\n","\n","  Average training loss: 0.30\n","  Training epcoh took: 0:33:10\n","\n","Running Validation...\n","  Accuracy: 0.93\n","  Validation Loss: 0.23\n","  Validation took: 0:00:54\n","\n","======== Epoch 2 / 2 ========\n","Training...\n","  Batch    40  of    594.    Elapsed: 0:02:14.\n","  Batch    80  of    594.    Elapsed: 0:04:33.\n","  Batch   120  of    594.    Elapsed: 0:06:52.\n","  Batch   160  of    594.    Elapsed: 0:09:07.\n","  Batch   200  of    594.    Elapsed: 0:11:21.\n","  Batch   240  of    594.    Elapsed: 0:13:35.\n","  Batch   280  of    594.    Elapsed: 0:15:50.\n","  Batch   320  of    594.    Elapsed: 0:18:05.\n","  Batch   360  of    594.    Elapsed: 0:20:20.\n","  Batch   400  of    594.    Elapsed: 0:22:34.\n","  Batch   440  of    594.    Elapsed: 0:24:49.\n","  Batch   480  of    594.    Elapsed: 0:27:04.\n","  Batch   520  of    594.    Elapsed: 0:29:18.\n","  Batch   560  of    594.    Elapsed: 0:31:32.\n","\n","  Average training loss: 0.10\n","  Training epcoh took: 0:33:25\n","\n","Running Validation...\n","  Accuracy: 0.94\n","  Validation Loss: 0.21\n","  Validation took: 0:00:54\n","\n","Training complete!\n","Total training took 1:08:32 (h:mm:ss)\n"]}],"source":["# For each epoch...\n","for epoch_i in range(0, epochs):\n","\n","    # ========================================\n","    #               Training\n","    # ========================================\n","\n","    # Perform one full pass over the training set.\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # Measure how long the training epoch takes.\n","    t0 = time.time()\n","\n","    # Reset the total loss for this epoch.\n","    total_train_loss = 0\n","\n","    # Put the model into training mode. Don't be mislead--the call to\n","    # `train` just changes the *mode*, it doesn't *perform* the training.\n","    # `dropout` and `batchnorm` layers behave differently during training\n","    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n","    model.train()\n","\n","    # For each batch of training data...\n","    for step, batch in enumerate(train_dataloader):\n","        # Progress update every 40 batches.\n","        if step % 40 == 0 and not step == 0:\n","            # Calculate elapsed time in minutes.\n","            elapsed = format_time(time.time() - t0)\n","\n","            # Report progress.\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        # Unpack this training batch from our dataloader.\n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using the\n","        # `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids\n","        #   [1]: attention masks\n","        #   [2]: labels\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        # Always clear any previously calculated gradients before performing a\n","        # backward pass. PyTorch doesn't do this automatically because\n","        # accumulating the gradients is \"convenient while training RNNs\".\n","        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n","        model.zero_grad()\n","\n","        # Perform a forward pass (evaluate the model on this training batch).\n","        # The documentation for this `model` function is here:\n","        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","        # It returns different numbers of parameters depending on what arguments\n","        # arge given and what flags are set. For our useage here, it returns\n","        # the loss (because we provided labels) and the \"logits\"--the model\n","        # outputs prior to activation.\n","        outputs = model(\n","            b_input_ids,\n","            token_type_ids=None,\n","            attention_mask=b_input_mask,\n","            labels=b_labels\n","        )\n","        loss = outputs[0]\n","        logits = outputs[1]\n","\n","        # Accumulate the training loss over all of the batches so that we can\n","        # calculate the average loss at the end. `loss` is a Tensor containing a\n","        # single value; the `.item()` function just returns the Python value\n","        # from the tensor.\n","        total_train_loss += loss.item()\n","\n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","\n","        # Clip the norm of the gradients to 1.0.\n","        # This is to help prevent the \"exploding gradients\" problem.\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # Update parameters and take a step using the computed gradient.\n","        # The optimizer dictates the \"update rule\"--how the parameters are\n","        # modified based on their gradients, the learning rate, etc.\n","        optimizer.step()\n","\n","        # Update the learning rate.\n","        scheduler.step()\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_train_loss = total_train_loss / len(train_dataloader)\n","\n","    # Measure how long this epoch took.\n","    training_time = format_time(time.time() - t0)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(training_time))\n","\n","    # ========================================\n","    #               Validation\n","    # ========================================\n","    # After the completion of each training epoch, measure our performance on\n","    # our validation set.\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","\n","    # Put the model in evaluation mode--the dropout layers behave differently\n","    # during evaluation.\n","    model.eval()\n","\n","    # Tracking variables\n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","    nb_eval_steps = 0\n","\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","\n","        # Unpack this training batch from our dataloader.\n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using\n","        # the `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids\n","        #   [1]: attention masks\n","        #   [2]: labels\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        # Tell pytorch not to bother with constructing the compute graph during\n","        # the forward pass, since this is only needed for backprop (training).\n","        with torch.no_grad():\n","            # Forward pass, calculate logit predictions.\n","            # token_type_ids is the same as the \"segment ids\", which\n","            # differentiates sentence 1 and 2 in 2-sentence tasks.\n","            # The documentation for this `model` function is here:\n","            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","            # Get the \"logits\" output by the model. The \"logits\" are the output\n","            # values prior to applying an activation function like the softmax.\n","            outputs = model(\n","                b_input_ids,\n","                token_type_ids=None,\n","                attention_mask=b_input_mask,\n","                labels=b_labels\n","            )\n","            loss = outputs[0]\n","            logits = outputs[1]\n","\n","        # Accumulate the validation loss.\n","        total_eval_loss += loss.item()\n","\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        # Calculate the accuracy for this batch of test sentences, and\n","        # accumulate it over all batches.\n","        total_eval_accuracy += flat_accuracy(logits, label_ids)\n","\n","\n","    # Report the final accuracy for this validation run.\n","    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n","    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_val_loss = total_eval_loss / len(validation_dataloader)\n","\n","    # Measure how long the validation run took.\n","    validation_time = format_time(time.time() - t0)\n","\n","    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n","    print(\"  Validation took: {:}\".format(validation_time))\n","\n","    # Record all statistics from this epoch.\n","    training_stats.append(\n","        {\n","            'epoch': epoch_i + 1,\n","            'Training Loss': avg_train_loss,\n","            'Valid. Loss': avg_val_loss,\n","            'Valid. Accur.': avg_val_accuracy,\n","            'Training Time': training_time,\n","            'Validation Time': validation_time\n","        }\n","    )\n","\n","print(\"\")\n","print(\"Training complete!\")\n","\n","print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"]},{"cell_type":"markdown","metadata":{},"source":["Running Validation...\n","* Accuracy: 0.94\n","* Validation Loss: 0.21\n","* Validation took: 0:00:54"]},{"cell_type":"markdown","metadata":{"id":"uc9_B_-OOplT"},"source":["### Saving the model"]},{"cell_type":"code","execution_count":160,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":599,"status":"ok","timestamp":1709469664000,"user":{"displayName":"Roger","userId":"07150139541907234973"},"user_tz":-60},"id":"bB4heCDFOpa6","outputId":"0548fd5c-7683-43b4-9cf5-8aa153ba851f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Saving model to ./two/\n"]},{"data":{"text/plain":["('./two/tokenizer_config.json',\n"," './two/special_tokens_map.json',\n"," './two/vocab.txt',\n"," './two/added_tokens.json')"]},"execution_count":160,"metadata":{},"output_type":"execute_result"}],"source":["import os\n","\n","# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n","\n","output_dir = './two/'\n","\n","# Create output directory if needed\n","if not os.path.exists(output_dir):\n","    os.makedirs(output_dir)\n","\n","print(\"Saving model to %s\" % output_dir)\n","\n","# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n","# They can then be reloaded using `from_pretrained()`\n","model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n","model_to_save.save_pretrained(output_dir)\n","fb_tokenizer.save_pretrained(output_dir)\n","\n","# Good practice: save your training arguments together with the trained model\n","# torch.save(args, os.path.join(output_dir, 'training_args.bin'))"]},{"cell_type":"markdown","metadata":{"id":"-LzpE6d89fn5"},"source":["## **Step 3: Deployment of the sentiment/category tagger on  financial news or social media posts**\n","\n","Let´s now turn our attention to a live deployment of the financial news tagger. Things can get quite complicated, specially if we add streaming data, so it is best to keep the deploymnet lightweight. There are mainly three important pieces. Let´s explore them:\n","\n","\n","- Build a local dashboard/app (e.g. using Streamlit or another web applications framework of your choice). A bit UI to display the sentiment tagger in action and demonstrate the practical application of your model.\n","\n","\n","- Build a financial news/alerts scraper pipeline, filter some entities if you focus your search. In a real world setting,  you’d likely want to build a more robust infrastructure for processing and ingestion of new examples, handling any preprocessing, and outputting predictions. Here are some options where to scrape data (real-time data might be expensive or limited):\n","\n","    - <span style=\"color:blue\">*Social Media Posts*</span>: Pulling historical or live data from tweets or reddit. There are public APIs with extensive documentation for them.\n","    - <span style=\"color:blue\">*OpenBB*</span>: Open research investment platform. It aggregates financial news across the world and has an API to access them.\n","    - <span style=\"color:blue\">*Financial news outlet*</span>: Yahoo Finance\n","    \n","An pipeline example: The basic premise is to read in a stream of tweets, use a lighweight sentiment analysis engine (BERT might not be a good fit here) to assign a bullish/neutral/bearish score to each tweet, and then see how this cumulatively changes over time.\n","    \n","    \n","- Build an inference endpoint for the tagging model. Within your infrastructure, you can deploy and load the resuting model. One way is to build a REST API endpoint, only to be queried locally (in your laptop).\n","\n","\n","\n","Extra: You could explore or quantify correlations with the market for a list of selected stock."]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"},"widgets":{"application/vnd.jupyter.widget-state+json":{"14f24652ef704f24b62a0f53a2757f2f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b09ef73f4fb54e4985f5652ed353a83d","placeholder":"​","style":"IPY_MODEL_3c36a721422643a8a844db6cb3b6b840","value":"vocab.txt: 100%"}},"17f1d2479c8c4ed08b9195a866b10363":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1896c674c33449c88bc15cd87c9e86a0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_14f24652ef704f24b62a0f53a2757f2f","IPY_MODEL_7965925578d64599af3c8d8ca2877d59","IPY_MODEL_7eb0946f2c394087827f4a5580be84eb"],"layout":"IPY_MODEL_f1ea13f042f24af4a6a70026a96d842d"}},"23019cfce2524c238d8dcce294756cad":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"24fb326b061f4b9d85b687d5cc9e4a5f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a8df236821e454fad3a3cfd5dcab400":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d837a311980742fe8f250d61521fe953","IPY_MODEL_d0362385031c47d7943ef15f0b3865c1","IPY_MODEL_5aaae4485d5f4cdb99c1f41343aa080e"],"layout":"IPY_MODEL_8d35c59d7f3544358dd841c867eb128a"}},"2eef6deb0a9b4c248819d7ee0d8615e3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"378a8e651a2d450aaa5f8d52447baf44":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ab82dee1ae34f7599a908efcc9d49a3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c36a721422643a8a844db6cb3b6b840":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"458dda8d76b0401ba7005f9f0bc8ad8a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"45df5879e4da42fc9cc42475b0a71655":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"525844abce5948668fd1ce22f287384b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_378a8e651a2d450aaa5f8d52447baf44","placeholder":"​","style":"IPY_MODEL_458dda8d76b0401ba7005f9f0bc8ad8a","value":"config.json: 100%"}},"5706bb5f168e477bb0eae7e275849070":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5aaae4485d5f4cdb99c1f41343aa080e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b09bcf4273ca4f68b87b6432edb33d47","placeholder":"​","style":"IPY_MODEL_a7447f5689f24af6af59b8f4c546a413","value":" 252/252 [00:00&lt;00:00, 19.2kB/s]"}},"621f6c89bcd245818d019330a96e07c9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"664939066eed4e589d098cf0f7857687":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_980c2dc2d9da4b57b20cd709e935fbdc","max":758,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8ec2a716b18340628469d69fad084219","value":758}},"69974d68e4a14896a00c1d35f964c05f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b3cb3de7b0b4fc28cbba52fe6c1356f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e9a49d30ab64a3bb99ea21d2e04e7ee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"76fb5090c2664a8187ac308dc7c932df":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7965925578d64599af3c8d8ca2877d59":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_886c19388efb4cbc86d770e5373fa6ec","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e1d0d6d4b4544a32ba1e0f6e7281d9c9","value":231508}},"7a4d6c97f9464d6184b2d1d76faf171f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_69974d68e4a14896a00c1d35f964c05f","placeholder":"​","style":"IPY_MODEL_23019cfce2524c238d8dcce294756cad","value":"special_tokens_map.json: 100%"}},"7ce66457b5334e0da42cd0db28ec00c5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_82c39b444c3d44b28442dc8fca784e5e","placeholder":"​","style":"IPY_MODEL_76fb5090c2664a8187ac308dc7c932df","value":"pytorch_model.bin: 100%"}},"7eb0946f2c394087827f4a5580be84eb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b3cb3de7b0b4fc28cbba52fe6c1356f","placeholder":"​","style":"IPY_MODEL_2eef6deb0a9b4c248819d7ee0d8615e3","value":" 232k/232k [00:00&lt;00:00, 14.0MB/s]"}},"82c39b444c3d44b28442dc8fca784e5e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"886c19388efb4cbc86d770e5373fa6ec":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d35c59d7f3544358dd841c867eb128a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ec2a716b18340628469d69fad084219":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"923bcab0332d4e099681d891f73f5afa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_621f6c89bcd245818d019330a96e07c9","placeholder":"​","style":"IPY_MODEL_952d24ab786945e1baec866e062ce520","value":" 438M/438M [00:01&lt;00:00, 258MB/s]"}},"92fd6e3bc7c04fac8f74b8ebb3c5b204":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"952d24ab786945e1baec866e062ce520":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"980c2dc2d9da4b57b20cd709e935fbdc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a54adea79e8a4c249d782eec3e9d0f37":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ab82dee1ae34f7599a908efcc9d49a3","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a77d166fa3ee45eeafb405d2e319ca79","value":112}},"a69dd001e14b486a911383797df843d1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_24fb326b061f4b9d85b687d5cc9e4a5f","placeholder":"​","style":"IPY_MODEL_bddbb3349d4c4be593554a7795628e17","value":" 758/758 [00:00&lt;00:00, 63.8kB/s]"}},"a7447f5689f24af6af59b8f4c546a413":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a77d166fa3ee45eeafb405d2e319ca79":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a91fe71fb7cf4bd0b048b557158d782e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aed9e18de6d54f27ab0a871c30492ae3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b09bcf4273ca4f68b87b6432edb33d47":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b09ef73f4fb54e4985f5652ed353a83d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4e48fc3fff74cf2ba3a515ef7e132ab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_525844abce5948668fd1ce22f287384b","IPY_MODEL_664939066eed4e589d098cf0f7857687","IPY_MODEL_a69dd001e14b486a911383797df843d1"],"layout":"IPY_MODEL_17f1d2479c8c4ed08b9195a866b10363"}},"bd3f8154203a47e9a8b767abc9fec3d5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7ce66457b5334e0da42cd0db28ec00c5","IPY_MODEL_ebcae7b262a143a6956f4190a9926afe","IPY_MODEL_923bcab0332d4e099681d891f73f5afa"],"layout":"IPY_MODEL_aed9e18de6d54f27ab0a871c30492ae3"}},"bddbb3349d4c4be593554a7795628e17":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bfd72d14f78a4b32a67daaf62e303659":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c61494619299461fbd01423bedd0734a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0362385031c47d7943ef15f0b3865c1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bfd72d14f78a4b32a67daaf62e303659","max":252,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f5b4f739ba0d450aba6ec23ec34a7499","value":252}},"d837a311980742fe8f250d61521fe953":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_92fd6e3bc7c04fac8f74b8ebb3c5b204","placeholder":"​","style":"IPY_MODEL_6e9a49d30ab64a3bb99ea21d2e04e7ee","value":"tokenizer_config.json: 100%"}},"e1d0d6d4b4544a32ba1e0f6e7281d9c9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e38482019e254d57a38546e90d32d263":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ebcae7b262a143a6956f4190a9926afe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e38482019e254d57a38546e90d32d263","max":437992753,"min":0,"orientation":"horizontal","style":"IPY_MODEL_45df5879e4da42fc9cc42475b0a71655","value":437992753}},"f1ea13f042f24af4a6a70026a96d842d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5b4f739ba0d450aba6ec23ec34a7499":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f7e36014ac35457e9fcf96342d5a8b01":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a91fe71fb7cf4bd0b048b557158d782e","placeholder":"​","style":"IPY_MODEL_5706bb5f168e477bb0eae7e275849070","value":" 112/112 [00:00&lt;00:00, 8.72kB/s]"}},"fa865818837749eb83085550cc464218":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7a4d6c97f9464d6184b2d1d76faf171f","IPY_MODEL_a54adea79e8a4c249d782eec3e9d0f37","IPY_MODEL_f7e36014ac35457e9fcf96342d5a8b01"],"layout":"IPY_MODEL_c61494619299461fbd01423bedd0734a"}}}}},"nbformat":4,"nbformat_minor":0}
